{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73907954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from Agent import Agent\n",
    "import re\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6747f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-base-v2')\n",
    "embeddings_model = AutoModel.from_pretrained('intfloat/e5-base-v2')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "embeddings_model.to(device)\n",
    "embeddings_model.eval()\n",
    "pass\n",
    "\n",
    "# for 'intfloat/e5-base-v2'\n",
    "# Each input text should start with \"query: \" or \"passage: \".\n",
    "# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1128202",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embeddings(texts):\n",
    "    # Tokenize the input texts\n",
    "    batch_dict = tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "    outputs = embeddings_model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask']).to('cpu')\n",
    "\n",
    "    # (Optionally) normalize embeddings\n",
    "    embeddings = F.normalize(embeddings)\n",
    "    return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7231d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chuncker:\n",
    "    def __init__(self, chunck_size=5, chunk_overlap=0):\n",
    "        #chunk_size is in words (after .split())\n",
    "        self.chunck_size = chunck_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "    def get_chunks(self, text):\n",
    "        all_words = text.split('.')\n",
    "        chunks = []\n",
    "        for i in range(0, len(all_words), self.chunck_size - self.chunk_overlap):\n",
    "            chunks.append('passage: ' + ' '.join(all_words[i:i+self.chunck_size]))\n",
    "        return chunks\n",
    "\n",
    "chunker = Chuncker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e880ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(embeddings_model.config.hidden_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c44c61ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:08<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "pdf_files = [x for x in os.listdir('.') if 'pdf' in x]\n",
    "text_info = []\n",
    "\n",
    "for file in tqdm(pdf_files):\n",
    "    reader = PdfReader(file)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        p_text = page.extract_text()\n",
    "        # Merge hyphenated words\n",
    "        p_text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", p_text)\n",
    "        # Fix newlines in the middle of sentences\n",
    "        p_text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", p_text.strip())\n",
    "        # Remove multiple newlines\n",
    "        p_text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", p_text)\n",
    "        text += p_text\n",
    "\n",
    "\n",
    "    text_chunks = chunker.get_chunks(text)\n",
    "    text_info.extend([(file, x) for x in text_chunks])\n",
    "    text_embeddings = np.array([get_embeddings([x]) for x in text_chunks]).reshape(len(text_chunks), -1)\n",
    "    index.add(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc5927ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, 'all_embeddings.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad8a3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(text_info, open('text_info.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3c380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
