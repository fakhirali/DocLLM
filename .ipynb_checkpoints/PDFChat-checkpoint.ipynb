{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76febc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM, AutoModelForSeq2SeqLM\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from Agent import Agent\n",
    "import re\n",
    "import faiss\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb44c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-base-v2')\n",
    "embeddings_model = AutoModel.from_pretrained('intfloat/e5-base-v2')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "embeddings_model.to(device)\n",
    "embeddings_model.eval()\n",
    "pass\n",
    "\n",
    "# for 'intfloat/e5-base-v2'\n",
    "# Each input text should start with \"query: \" or \"passage: \".\n",
    "# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b00a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embeddings(texts):\n",
    "    # Tokenize the input texts\n",
    "    batch_dict = tokenizer(texts, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "    outputs = embeddings_model(**batch_dict)\n",
    "    embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask']).to('cpu')\n",
    "\n",
    "    # (Optionally) normalize embeddings\n",
    "    embeddings = F.normalize(embeddings)\n",
    "    return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93143863",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index('all_embeddings.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7abdc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_info = pkl.load(open('text_info.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "798a3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is the difference between an encoder and a decoder?'\n",
    "query = 'query: ' + query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29fa1064",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = get_embeddings([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "021e491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a66c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, text_idx = index.search(query_embedding,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb50f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_idx = text_idx.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "911dc1b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12, 383,  22])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38a01cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30136153, 0.35455027, 0.35456172]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4cd5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = '.'.join(np.array(text_info)[text_idx][:,1])\n",
    "info = info.replace('passage: ', '').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bec40fdd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Figure 1: The Transformer - model architecture  3 1 Encoder and Decoder Stacks Encoder: The encoder is composed of a stack of N= 6 identical layers  Each layer has two sub-layers  The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, positionwise fully connected feed-forward network. ⟨decoder⟩denotes the decoding procedure employed by the LMQL runtime when solving the query  The presented version of LMQL enables argmax ,sample and beam argmax and sample work as discussed in §2 1  beamhowever, denotes a novel procedure called scripted beam search which performs beam search jointly over all holes and control flow. \u000fThe encoder contains self-attention layers  In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder  Each position in the encoder can attend to all positions in the previous layer of the encoder  \u000fSimilarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position  We need to prevent leftward information ﬂow in the decoder to preserve the auto-regressive property\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "605634ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'databricks/dolly-v2-3b'\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             torch_dtype=torch.bfloat16,\n",
    "                                            low_cpu_mem_usage=True,\n",
    "                                                 trust_remote_code=True)\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "gen_model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d06c2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = gen_tokenizer('Human: What is your name?\\n Assistant: ', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c07a492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "Below is an user query that describes a question. Write a response that appropriately answers the query using the \n",
    "information given in the input. The information is extracted from a research paper.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "agent = Agent(gen_model, gen_tokenizer, prompt,\n",
    "              break_words=['### End'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a89f270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_text = f'### Instruction:\\n{query.replace(\"query: \", \"\")}\\n\\nInput:\\n{info}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7883699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "What is the difference between an encoder and a decoder?\n",
      "\n",
      "Input:\n",
      "2Figure 1: The Transformer - model architecture  3 1 Encoder and Decoder Stacks Encoder: The encoder is composed of a stack of N= 6 identical layers  Each layer has two sub-layers  The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, positionwise fully connected feed-forward network. ⟨decoder⟩denotes the decoding procedure employed by the LMQL runtime when solving the query  The presented version of LMQL enables argmax ,sample and beam argmax and sample work as discussed in §2 1  beamhowever, denotes a novel procedure called scripted beam search which performs beam search jointly over all holes and control flow. \u000fThe encoder contains self-attention layers  In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder  Each position in the encoder can attend to all positions in the previous layer of the encoder  \u000fSimilarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position  We need to prevent leftward information ﬂow in the decoder to preserve the auto-regressive property\n"
     ]
    }
   ],
   "source": [
    "print(gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c75d8f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The decoder contains self-attention layers which allow each position in the decoder to attend to all positions in the decoder up to and including that position.\n",
      "\n",
      "### End"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThe decoder contains self-attention layers which allow each position in the decoder to attend to all positions in the decoder up to and including that position.\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.generate_response_greedy(gen_text,\n",
    "                               verbose=True, temp=0.5,name='### Response:',max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1972224b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
